import streamlit as st
import numpy as np
import librosa
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from PIL import Image, ImageDraw, ImageFont
import io
import tempfile
import os
import random
from datetime import datetime

class VoiceAnalyzer:
    def __init__(self):
        self.sample_rate = 22050
        self.metrics_names = {
            'volume': 'å£°ã®å¤§ãã•',
            'clarity': 'å£°ã®æ˜ç­åº¦',
            'pitch_stability': 'éŸ³ç¨‹ã®å®‰å®šæ€§',
            'rhythm': 'ãƒªã‚ºãƒ ãƒ»ãƒ†ãƒ³ãƒ',
            'expression': 'è¡¨ç¾åŠ›',
            'resonance': 'å£°ã®éŸ¿ã'
        }
        
    def load_audio(self, audio_file):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{audio_file.name.split(".")[-1]}') as tmp_file:
            tmp_file.write(audio_file.getvalue())
            tmp_file_path = tmp_file.name
        
        try:
            # ã‚ˆã‚Šå®‰å®šã—ãŸéŸ³å£°èª­ã¿è¾¼ã¿
            import warnings
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                y, sr = librosa.load(tmp_file_path, sr=self.sample_rate, duration=30)
            
            duration = len(y) / sr
            
            # 30ç§’ä»¥ä¸‹ã®éŸ³å£°ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼
            if duration < 30:
                os.unlink(tmp_file_path)
                return None, None, duration
                
            # 30ç§’ã«ãƒˆãƒªãƒŸãƒ³ã‚°
            y = y[:int(30 * sr)]
            
            os.unlink(tmp_file_path)
            return y, sr, 30.0
            
        except Exception as e:
            if os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)
            raise e
    
    def analyze_voice(self, y, sr, purpose):
        """éŸ³å£°ã‚’åˆ†æã—ã¦6ã¤ã®æŒ‡æ¨™ã‚’è¨ˆç®—"""
        metrics = {}
        
        # 1. å£°ã®å¤§ãã•ï¼ˆRMSã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
        rms = np.sqrt(np.mean(y**2))
        # ç„¡éŸ³éƒ¨åˆ†ã‚’é™¤å¤–ã—ãŸè¨ˆç®—
        non_silent = y[np.abs(y) > 0.01]
        if len(non_silent) > 0:
            rms_non_silent = np.sqrt(np.mean(non_silent**2))
            volume_score = min(99, int(rms_non_silent * 500))
        else:
            volume_score = 10
        metrics['volume'] = volume_score
        
        # 2. å£°ã®æ˜ç­åº¦ï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒï¼‰
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        clarity_score = min(99, int(np.mean(spectral_centroids) / 40))
        metrics['clarity'] = clarity_score
        
        # 3. éŸ³ç¨‹ã®å®‰å®šæ€§ï¼ˆãƒ”ãƒƒãƒã®æ¨™æº–åå·®ï¼‰
        pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
        pitch_values = []
        for t in range(pitches.shape[1]):
            index = magnitudes[:, t].argmax()
            pitch = pitches[index, t]
            if pitch > 0:
                pitch_values.append(pitch)
        
        if len(pitch_values) > 0:
            pitch_std = np.std(pitch_values)
            pitch_stability = max(10, min(99, int(99 - pitch_std / 10)))
        else:
            pitch_stability = 50
        metrics['pitch_stability'] = pitch_stability
        
        # 4. ãƒªã‚ºãƒ ãƒ»ãƒ†ãƒ³ãƒï¼ˆãƒ†ãƒ³ãƒæ¤œå‡ºï¼‰
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
        if purpose == "speaking":
            # è©±ã—å£°ã®å ´åˆã€é©åº¦ãªãƒ†ãƒ³ãƒãŒè‰¯ã„
            rhythm_score = min(99, int(50 + abs(120 - tempo) / 2))
        else:
            # æ­Œã‚„ãƒ—ãƒ¬ã‚¼ãƒ³ã®å ´åˆã€å®‰å®šã—ãŸãƒ†ãƒ³ãƒãŒè‰¯ã„
            rhythm_score = min(99, int(tempo / 2))
        metrics['rhythm'] = rhythm_score
        
        # 5. è¡¨ç¾åŠ›ï¼ˆãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ãƒ¬ãƒ³ã‚¸ï¼‰
        db = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
        dynamic_range = np.max(db) - np.mean(db[db > -80])
        expression_score = min(99, int(dynamic_range * 2))
        metrics['expression'] = expression_score
        
        # 6. å£°ã®éŸ¿ãï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ­ãƒ¼ãƒ«ã‚ªãƒ•ï¼‰
        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
        resonance_score = min(99, int(np.mean(rolloff) / 50))
        metrics['resonance'] = resonance_score
        
        # ç›®çš„åˆ¥ã®é‡ã¿ä»˜ã‘èª¿æ•´
        if purpose == "singing":
            metrics['pitch_stability'] = min(99, int(metrics['pitch_stability'] * 1.2))
            metrics['expression'] = min(99, int(metrics['expression'] * 1.1))
        elif purpose == "speaking":
            metrics['clarity'] = min(99, int(metrics['clarity'] * 1.2))
            metrics['rhythm'] = min(99, int(metrics['rhythm'] * 1.1))
        elif purpose == "presentation":
            metrics['volume'] = min(99, int(metrics['volume'] * 1.1))
            metrics['clarity'] = min(99, int(metrics['clarity'] * 1.1))
        
        return metrics, y, sr
    
    def create_radar_chart(self, metrics, title="éŸ³å£°åˆ†æçµæœ"):
        """ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
        categories = list(self.metrics_names.values())
        values = [metrics[key] for key in self.metrics_names.keys()]
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=categories,
            fill='toself',
            name='ã‚¹ã‚³ã‚¢',
            line_color='rgb(50, 150, 255)',
            fillcolor='rgba(50, 150, 255, 0.3)'
        ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 100]
                )),
            title=title,
            showlegend=False,
            height=500
        )
        
        return fig
    
    def create_waveform(self, y, sr):
        """æ³¢å½¢ã‚’æç”»"""
        fig, ax = plt.subplots(figsize=(12, 4))
        time = np.linspace(0, len(y) / sr, len(y))
        ax.plot(time, y, color='blue', alpha=0.7)
        ax.set_xlabel('æ™‚é–“ (ç§’)')
        ax.set_ylabel('æŒ¯å¹…')
        ax.set_title('éŸ³å£°æ³¢å½¢')
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        return fig
    
    def create_spectrogram(self, y, sr):
        """ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‚’æç”»"""
        fig, ax = plt.subplots(figsize=(12, 6))
        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
        img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=ax)
        fig.colorbar(img, ax=ax, format='%+2.0f dB')
        ax.set_title('ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ')
        plt.tight_layout()
        return fig
    
    def get_evaluation_level(self, total_score):
        """ç·åˆã‚¹ã‚³ã‚¢ã‹ã‚‰5æ®µéšè©•ä¾¡ã‚’è¿”ã™"""
        if total_score >= 450:
            return "S", "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒ™ãƒ«"
        elif total_score >= 400:
            return "A", "éå¸¸ã«å„ªç§€"
        elif total_score >= 350:
            return "B", "è‰¯å¥½"
        elif total_score >= 300:
            return "C", "æ¨™æº–çš„"
        else:
            return "D", "æ”¹å–„ã®ä½™åœ°ã‚ã‚Š"
    
    def generate_diagnosis(self, metrics, purpose, name):
        """AIè¨ºæ–­ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        total_score = sum(metrics.values())
        level, level_desc = self.get_evaluation_level(total_score)
        
        # è¤‡æ•°ã®è¨ºæ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”¨æ„
        patterns = {
            "S": [
                f"{name}ã®å£°ã¯ç´ æ™´ã‚‰ã—ã„å®Œæˆåº¦ã§ã™ï¼ãƒ—ãƒ­ã®é ˜åŸŸã«é”ã—ã¦ãŠã‚Šã€ã™ã¹ã¦ã®æŒ‡æ¨™ã§é«˜ã„ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã£ã¦ã„ã¾ã™ã€‚",
                f"é©šç•°çš„ãªå£°è³ªã§ã™ï¼{name}ã®å£°ã¯ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã¨ã—ã¦é€šç”¨ã™ã‚‹å®ŸåŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚",
                f"{name}ã®å£°ã®å®Œæˆåº¦ã¯æ¥µã‚ã¦é«˜ã„ã§ã™ã€‚å…¨ä½“çš„ãªãƒãƒ©ãƒ³ã‚¹ãŒç´ æ™´ã‚‰ã—ãã€ãƒ—ãƒ­ç´šã®å®ŸåŠ›ã¨ã„ãˆã‚‹ã§ã—ã‚‡ã†ã€‚"
            ],
            "A": [
                f"{name}ã®å£°ã¯éå¸¸ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚ã‚‚ã†å°‘ã—ã®ç·´ç¿’ã§ãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«ã«åˆ°é”ã§ãã‚‹ç´ è³ªã‚’æŒã£ã¦ã„ã¾ã™ã€‚",
                f"ç´ æ™´ã‚‰ã—ã„å£°è³ªã§ã™ï¼{name}ã®å£°ã¯é«˜ã„å®Œæˆåº¦ã‚’èª‡ã‚Šã€ã•ã‚‰ãªã‚‹å‘ä¸Šã®å¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ã„ã¾ã™ã€‚",
                f"{name}ã®å£°ã¯éå¸¸ã«è‰¯å¥½ã§ã™ã€‚ç¾åœ¨ã®å®ŸåŠ›ã‚’ç¶­æŒã—ãªãŒã‚‰ã€ã•ã‚‰ã«ç£¨ãã‚’ã‹ã‘ã¦ã„ãã¾ã—ã‚‡ã†ã€‚"
            ],
            "B": [
                f"{name}ã®å£°ã¯è‰¯å¥½ãªçŠ¶æ…‹ã§ã™ã€‚ã„ãã¤ã‹ã®æ”¹å–„ç‚¹ã«å–ã‚Šçµ„ã‚€ã“ã¨ã§ã€ã•ã‚‰ãªã‚‹å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚",
                f"è‰¯ã„å£°ã‚’ãŠæŒã¡ã§ã™ï¼{name}ã®å£°ã«ã¯ã¾ã ä¼¸ã³ã—ã‚ãŒã‚ã‚Šã€ç·´ç¿’æ¬¡ç¬¬ã§å¤§ããå‘ä¸Šã™ã‚‹ã§ã—ã‚‡ã†ã€‚",
                f"{name}ã®å£°ã¯åŸºæœ¬çš„ãªè¦ç´ ãŒæ•´ã£ã¦ã„ã¾ã™ã€‚ç‰¹å®šã®åˆ†é‡ã‚’é‡ç‚¹çš„ã«ç·´ç¿’ã™ã‚‹ã“ã¨ã§é£›èºçš„ãªæˆé•·ãŒå¯èƒ½ã§ã™ã€‚"
            ],
            "C": [
                f"{name}ã®å£°ã¯æ¨™æº–çš„ãªãƒ¬ãƒ™ãƒ«ã§ã™ã€‚åŸºç¤ã‹ã‚‰ã—ã£ã‹ã‚Šç·´ç¿’ã™ã‚‹ã“ã¨ã§ã€ç¢ºå®Ÿã«ä¸Šé”ã—ã¦ã„ã‘ã‚‹ã§ã—ã‚‡ã†ã€‚",
                f"ç¾åœ¨ã®{name}ã®å£°ã¯å¹³å‡çš„ã§ã™ãŒã€é©åˆ‡ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§å¤§ããæ”¹å–„ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
                f"{name}ã®å£°ã«ã¯æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚ç„¦ã‚‰ãšåŸºæœ¬ã‹ã‚‰ç©ã¿ä¸Šã’ã¦ã„ãã“ã¨ã§ã€ç€å®Ÿã«æˆé•·ã§ãã¾ã™ã€‚"
            ],
            "D": [
                f"{name}ã®å£°ã«ã¯ã¾ã å¤šãã®æ”¹å–„ç‚¹ãŒã‚ã‚Šã¾ã™ãŒã€ãã‚Œã¯æˆé•·ã®å¯èƒ½æ€§ãŒå¤§ãã„ã¨ã„ã†ã“ã¨ã§ã™ã€‚åŸºç¤ç·´ç¿’ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚",
                f"ç¾åœ¨ã®{name}ã®å£°ã¯ç™ºå±•é€”ä¸Šã§ã™ã€‚ãƒ—ãƒ­ã®æŒ‡å°ã‚’å—ã‘ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«ä¸Šé”ã§ãã‚‹ã§ã—ã‚‡ã†ã€‚",
                f"{name}ã®å£°ã¯æ”¹å–„ã®ä½™åœ°ãŒå¤§ã„ã«ã‚ã‚Šã¾ã™ã€‚æ­£ã—ã„æ–¹æ³•ã§ç·´ç¿’ã™ã‚Œã°ã€å¿…ãšä¸Šé”ã—ã¾ã™ã€‚"
            ]
        }
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«è¨ºæ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
        diagnosis = random.choice(patterns[level])
        
        # å¼±ç‚¹ã®åˆ†æ
        weak_points = []
        for metric, value in metrics.items():
            if value < 60:
                weak_points.append((self.metrics_names[metric], value))
        
        weak_points.sort(key=lambda x: x[1])
        
        if weak_points:
            diagnosis += f"\n\nç‰¹ã«ã€Œ{weak_points[0][0]}ã€ï¼ˆ{weak_points[0][1]}ç‚¹ï¼‰"
            if len(weak_points) > 1:
                diagnosis += f"ã¨ã€Œ{weak_points[1][0]}ã€ï¼ˆ{weak_points[1][1]}ç‚¹ï¼‰"
            diagnosis += "ã®æ”¹å–„ã«æ³¨åŠ›ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
        
        # æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ
        hints = []
        if metrics['volume'] < 60:
            hints.append("ãƒ»å‘¼å¸ã‚’ã—ã£ã‹ã‚Šä½¿ã†ãŸã‚ã«ã€è…¹å¼å‘¼å¸ã®ç·´ç¿’ã‚’è¡Œã„ã¾ã—ã‚‡ã†")
        if metrics['clarity'] < 60:
            hints.append("ãƒ»æ»‘èˆŒã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã€å£ã®é–‹ãæ–¹ã¨èˆŒã®ä½ç½®ã‚’æ„è­˜ã—ã¾ã—ã‚‡ã†")
        if metrics['pitch_stability'] < 60:
            hints.append("ãƒ»éŸ³ç¨‹ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ã€ãƒ­ãƒ³ã‚°ãƒˆãƒ¼ãƒ³ã®ç·´ç¿’ã‚’å–ã‚Šå…¥ã‚Œã¾ã—ã‚‡ã†")
        if metrics['rhythm'] < 60:
            hints.append("ãƒ»ãƒªã‚ºãƒ æ„Ÿã‚’é¤Šã†ãŸã‚ã€ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ ã‚’ä½¿ã£ãŸç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†")
        if metrics['expression'] < 60:
            hints.append("ãƒ»è¡¨ç¾åŠ›ã‚’é«˜ã‚ã‚‹ãŸã‚ã€æ„Ÿæƒ…ã‚’è¾¼ã‚ãŸæœ—èª­ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†")
        if metrics['resonance'] < 60:
            hints.append("ãƒ»å£°ã®éŸ¿ãã‚’è‰¯ãã™ã‚‹ãŸã‚ã€å…±é³´è…”ã‚’æ„è­˜ã—ãŸç™ºå£°ç·´ç¿’ã‚’ã—ã¾ã—ã‚‡ã†")
        
        if hints:
            diagnosis += "\n\nã€æ”¹å–„ã®ãƒ’ãƒ³ãƒˆã€‘\n" + "\n".join(hints)
        
        return diagnosis, total_score, level, level_desc
    
    def create_result_image(self, name, metrics, diagnosis, total_score, level, radar_fig):
        """çµæœã‚’ç”»åƒã¨ã—ã¦å‡ºåŠ›ï¼ˆJPGå½¢å¼ï¼‰"""
        # ç”»åƒã‚µã‚¤ã‚º
        width = 1080
        height = 1920
        
        # èƒŒæ™¯ç”»åƒã‚’ä½œæˆ
        img = Image.new('RGB', (width, height), color='white')
        draw = ImageDraw.Draw(img)
        
        # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã®è¨­å®š
        try:
            title_font = ImageFont.truetype("Arial.ttf", 60)
            header_font = ImageFont.truetype("Arial.ttf", 48)
            text_font = ImageFont.truetype("Arial.ttf", 36)
            small_font = ImageFont.truetype("Arial.ttf", 28)
        except:
            title_font = ImageFont.load_default()
            header_font = ImageFont.load_default()
            text_font = ImageFont.load_default()
            small_font = ImageFont.load_default()
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        y_pos = 50
        draw.text((width//2, y_pos), "éŸ³å£°åˆ†æçµæœ", font=title_font, fill='black', anchor="mt")
        
        # åå‰ã¨æ—¥ä»˜
        y_pos += 100
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        draw.text((width//2, y_pos), f"{name} - {date_str}", font=text_font, fill='gray', anchor="mt")
        
        # ç·åˆã‚¹ã‚³ã‚¢
        y_pos += 80
        draw.text((width//2, y_pos), f"ç·åˆã‚¹ã‚³ã‚¢: {total_score}/594ç‚¹", font=header_font, fill='black', anchor="mt")
        
        # ãƒ¬ãƒ™ãƒ«è©•ä¾¡
        y_pos += 70
        level_color = {
            "S": "gold",
            "A": "blue", 
            "B": "green",
            "C": "orange",
            "D": "red"
        }.get(level, "black")
        draw.text((width//2, y_pos), f"è©•ä¾¡: {level} - {level_desc}", font=text_font, fill=level_color, anchor="mt")
        
        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ç”»åƒã«å¤‰æ›ã—ã¦è²¼ã‚Šä»˜ã‘
        y_pos += 80
        radar_img_buf = io.BytesIO()
        radar_fig.write_image(radar_img_buf, format='png', width=800, height=600)
        radar_img_buf.seek(0)
        radar_img = Image.open(radar_img_buf)
        radar_img = radar_img.resize((800, 600), Image.Resampling.LANCZOS)
        img.paste(radar_img, ((width - 800) // 2, y_pos))
        
        # å„æŒ‡æ¨™ã®ã‚¹ã‚³ã‚¢
        y_pos += 650
        draw.text((width//2, y_pos), "è©³ç´°ã‚¹ã‚³ã‚¢", font=header_font, fill='black', anchor="mt")
        y_pos += 70
        
        for key, name_jp in self.metrics_names.items():
            score = metrics[key]
            draw.text((150, y_pos), f"{name_jp}:", font=text_font, fill='black')
            draw.text((600, y_pos), f"{score}ç‚¹", font=text_font, fill='black')
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            bar_width = 300
            bar_height = 20
            bar_x = 700
            draw.rectangle([bar_x, y_pos - 10, bar_x + bar_width, y_pos + bar_height - 10], outline='gray', width=2)
            fill_width = int(bar_width * score / 100)
            if fill_width > 0:
                draw.rectangle([bar_x, y_pos - 10, bar_x + fill_width, y_pos + bar_height - 10], fill='lightblue')
            
            y_pos += 50
        
        # AIè¨ºæ–­
        y_pos += 50
        draw.text((width//2, y_pos), "AIè¨ºæ–­", font=header_font, fill='black', anchor="mt")
        y_pos += 70
        
        # è¨ºæ–­ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ˜ã‚Šè¿”ã—
        lines = []
        current_line = ""
        for char in diagnosis:
            if char == '\n':
                if current_line:
                    lines.append(current_line)
                    current_line = ""
                lines.append("")
            else:
                current_line += char
                if len(current_line) >= 25:  # 25æ–‡å­—ã§æŠ˜ã‚Šè¿”ã—
                    lines.append(current_line)
                    current_line = ""
        if current_line:
            lines.append(current_line)
        
        for line in lines:
            if line:
                draw.text((100, y_pos), line, font=small_font, fill='black')
            y_pos += 40
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        y_pos = height - 100
        draw.text((width//2, y_pos), "Â© 2024 Voice Analysis AI", font=small_font, fill='gray', anchor="mt")
        
        # JPGå½¢å¼ã§ä¿å­˜
        output = io.BytesIO()
        img.save(output, format='JPEG', quality=95)
        output.seek(0)
        
        return output

def main():
    st.set_page_config(page_title="AIéŸ³å£°åˆ†æ", page_icon="ğŸ¤", layout="wide")
    
    st.title("ğŸ¤ AIéŸ³å£°åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("""
    ã‚ãªãŸã®å£°ã‚’6ã¤ã®æŒ‡æ¨™ã§ç§‘å­¦çš„ã«åˆ†æã—ã€æ”¹å–„ç‚¹ã‚’AIãŒè¨ºæ–­ã—ã¾ã™ã€‚
    30ç§’ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
    """)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'result_image' not in st.session_state:
        st.session_state.result_image = None
    
    analyzer = VoiceAnalyzer()
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    with st.form("analysis_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            name = st.text_input("ãŠåå‰", placeholder="å¿…é ˆ", help="åˆ†æçµæœã«è¡¨ç¤ºã•ã‚Œã¾ã™")
        
        with col2:
            purpose = st.selectbox(
                "åˆ†æç›®çš„ã‚’é¸æŠ",
                ["", "singing", "speaking", "presentation"],
                format_func=lambda x: {
                    "": "é¸æŠã—ã¦ãã ã•ã„ï¼ˆå¿…é ˆï¼‰",
                    "singing": "æ­Œå”±åŠ›å‘ä¸Š",
                    "speaking": "è©±ã—æ–¹æ”¹å–„", 
                    "presentation": "ãƒ—ãƒ¬ã‚¼ãƒ³åŠ›å‘ä¸Š"
                }.get(x, x)
            )
        
        audio_file = st.file_uploader(
            "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['wav', 'mp3', 'm4a', 'flac'],
            help="30ç§’ä»¥ä¸Šã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™"
        )
        
        submitted = st.form_submit_button("åˆ†æé–‹å§‹", type="primary", use_container_width=True)
    
    if submitted:
        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if not name:
            st.error("ãŠåå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        
        if not purpose:
            st.error("åˆ†æç›®çš„ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return
            
        if not audio_file:
            st.error("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åå‰ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_name = f"{name}ã•ã‚“"
        
        # åˆ†æå‡¦ç†
        with st.spinner('éŸ³å£°ã‚’åˆ†æä¸­...'):
            try:
                # éŸ³å£°ã®èª­ã¿è¾¼ã¿
                y, sr, duration = analyzer.load_audio(audio_file)
                
                if y is None:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯30ç§’ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ï¼ˆç¾åœ¨: {duration:.1f}ç§’ï¼‰")
                    return
                
                # éŸ³å£°åˆ†æ
                metrics, y_trimmed, sr = analyzer.analyze_voice(y, sr, purpose)
                
                # AIè¨ºæ–­
                diagnosis, total_score, level, level_desc = analyzer.generate_diagnosis(metrics, purpose, formatted_name)
                
                # çµæœè¡¨ç¤º
                st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                st.subheader("ğŸ“Š åˆ†æçµæœ")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ç·åˆã‚¹ã‚³ã‚¢", f"{total_score}/594ç‚¹")
                with col2:
                    st.metric("è©•ä¾¡ãƒ¬ãƒ™ãƒ«", level)
                with col3:
                    st.metric("ãƒ¬ãƒ™ãƒ«èª¬æ˜", level_desc)
                
                # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
                radar_fig = analyzer.create_radar_chart(metrics, f"{formatted_name}ã®éŸ³å£°åˆ†æçµæœ")
                st.plotly_chart(radar_fig, use_container_width=True)
                
                # è©³ç´°ã‚¹ã‚³ã‚¢
                st.subheader("ğŸ“ˆ è©³ç´°ã‚¹ã‚³ã‚¢")
                cols = st.columns(3)
                for i, (key, name_jp) in enumerate(analyzer.metrics_names.items()):
                    with cols[i % 3]:
                        st.metric(name_jp, f"{metrics[key]}ç‚¹")
                
                # AIè¨ºæ–­çµæœ
                st.subheader("ğŸ¤– AIè¨ºæ–­")
                st.info(diagnosis)
                
                # éŸ³å£°æ³¢å½¢ã¨ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ 
                with st.expander("ğŸ”Š è©³ç´°ãªéŸ³å£°åˆ†æãƒ‡ãƒ¼ã‚¿"):
                    tab1, tab2 = st.tabs(["æ³¢å½¢", "ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ "])
                    
                    with tab1:
                        waveform_fig = analyzer.create_waveform(y_trimmed, sr)
                        st.pyplot(waveform_fig)
                    
                    with tab2:
                        spectrogram_fig = analyzer.create_spectrogram(y_trimmed, sr)
                        st.pyplot(spectrogram_fig)
                
                # çµæœç”»åƒã®ç”Ÿæˆ
                result_image = analyzer.create_result_image(
                    formatted_name, metrics, diagnosis, total_score, level, radar_fig
                )
                st.session_state.result_image = result_image
                st.session_state.analysis_complete = True
                
            except Exception as e:
                import traceback
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.error(f"è©³ç´°: {traceback.format_exc()}")
                return
    
    # ãƒ“ã‚¸ãƒã‚¹CTAã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if st.session_state.analysis_complete:
        st.markdown("---")
        
        # CTAãƒœã‚¿ãƒ³ã‚’å¤§ããç›®ç«‹ãŸã›ã‚‹
        st.markdown("""
        <div style="background-color: #f0f8ff; padding: 30px; border-radius: 10px; text-align: center;">
            <h2 style="color: #1f77b4;">ğŸ¯ ãƒ—ãƒ­ã®æŒ‡å°ã§å£°ã‚’å¤‰ãˆã¾ã›ã‚“ã‹ï¼Ÿ</h2>
            <p style="font-size: 18px; margin: 20px 0;">
                AIåˆ†æã®çµæœã‚’åŸºã«ã€ãƒ—ãƒ­ã®ãƒœã‚¤ã‚¹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒã‚ãªãŸã«æœ€é©ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒ³ã‚’ææ¡ˆã—ã¾ã™ã€‚
            </p>
            <p style="font-size: 24px; font-weight: bold; color: #ff6b6b; margin: 20px 0;">
                åˆå›ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚° Â¥9,800ï¼ˆé€šå¸¸Â¥15,000ï¼‰
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ“ ç„¡æ–™ç›¸è«‡ã‚’äºˆç´„ã™ã‚‹", type="primary", use_container_width=True):
                st.balloons()
                st.success("äºˆç´„ãƒ•ã‚©ãƒ¼ãƒ ã«ç§»å‹•ã—ã¾ã™...")
                # ã“ã“ã«äºˆç´„ãƒ•ã‚©ãƒ¼ãƒ ã¸ã®ãƒªãƒ³ã‚¯ã‚„å‡¦ç†ã‚’è¿½åŠ 
        
        # ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã¯æ§ãˆã‚ã«é…ç½®
        st.markdown("---")
        st.markdown("### ğŸ“¸ åˆ†æçµæœã‚’ã‚·ã‚§ã‚¢")
        
        if st.session_state.result_image:
            col1, col2, col3 = st.columns([2, 1, 2])
            with col2:
                st.download_button(
                    label="ç”»åƒã¨ã—ã¦ä¿å­˜",
                    data=st.session_state.result_image,
                    file_name=f"voice_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg",
                    mime="image/jpeg",
                    help="SNSã§ã‚·ã‚§ã‚¢ã§ãã‚‹ç”»åƒã¨ã—ã¦ä¿å­˜ã—ã¾ã™"
                )

if __name__ == "__main__":
    main()